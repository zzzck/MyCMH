è·¨æ¨¡æ€å“ˆå¸Œæ£€ç´¢ (Cross-Modal Hash Retrieval)
æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªå®Œæ•´çš„è·¨æ¨¡æ€å“ˆå¸Œæ£€ç´¢ç³»ç»Ÿï¼Œæ”¯æŒæ–‡æœ¬-å›¾åƒä¹‹é—´çš„é«˜æ•ˆæ£€ç´¢ã€‚æ¨¡å‹å°†æ–‡æœ¬å’Œå›¾åƒç¼–ç ä¸ºç´§å‡‘çš„å“ˆå¸Œç ï¼ˆå€¼åœ¨-1åˆ°1ä¹‹é—´ï¼‰ï¼Œå®ç°å¿«é€Ÿçš„è·¨æ¨¡æ€æ£€ç´¢ã€‚

ğŸš€ ä¸»è¦ç‰¹æ€§
è·¨æ¨¡æ€å“ˆå¸Œç¼–ç : å°†æ–‡æœ¬å’Œå›¾åƒæ˜ å°„åˆ°ç»Ÿä¸€çš„å“ˆå¸Œç©ºé—´
é«˜æ•ˆæ£€ç´¢: ä½¿ç”¨æ±‰æ˜è·ç¦»è¿›è¡Œå¿«é€Ÿç›¸ä¼¼åº¦è®¡ç®—
çµæ´»çš„æ¨¡å‹æ¶æ„: æ”¯æŒå¤šç§æ–‡æœ¬ç¼–ç å™¨ï¼ˆBERTç³»åˆ—ï¼‰å’Œå›¾åƒç¼–ç å™¨ï¼ˆResNetã€ViTï¼‰
å®Œæ•´çš„è®­ç»ƒæµç¨‹: åŒ…å«å¯¹æ¯”å­¦ä¹ ã€é‡åŒ–æŸå¤±ã€å¹³è¡¡æŸå¤±ç­‰
ä¸°å¯Œçš„è¯„ä¼°æŒ‡æ ‡: mAPã€Precision@Kã€Recall@Kã€NDCG@Kç­‰
å¤šæ•°æ®é›†æ”¯æŒ: COCOã€Flickr30Kã€åˆæˆæ•°æ®é›†
æ˜“äºä½¿ç”¨: æä¾›å®Œæ•´çš„è®­ç»ƒå’Œæ¨ç†è„šæœ¬
ğŸ“ é¡¹ç›®ç»“æ„
cross_modal_hash_retrieval/
â”œâ”€â”€ models/                    # æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cross_modal_hash.py   # ä¸»æ¨¡å‹å’ŒæŸå¤±å‡½æ•°
â”‚   â”œâ”€â”€ text_encoder.py       # æ–‡æœ¬ç¼–ç å™¨
â”‚   â”œâ”€â”€ image_encoder.py      # å›¾åƒç¼–ç å™¨
â”‚   â””â”€â”€ hash_layer.py         # å“ˆå¸Œå±‚
â”œâ”€â”€ data/                     # æ•°æ®å¤„ç†
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ dataset.py           # æ•°æ®é›†ç±»
â”‚   â”œâ”€â”€ dataloader.py        # æ•°æ®åŠ è½½å™¨
â”‚   â””â”€â”€ transforms.py        # æ•°æ®å˜æ¢
â”œâ”€â”€ training/                # è®­ç»ƒæ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ trainer.py          # è®­ç»ƒå™¨
â”‚   â”œâ”€â”€ optimizer.py        # ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
â”‚   â””â”€â”€ config.py           # è®­ç»ƒé…ç½®
â”œâ”€â”€ evaluation/             # è¯„ä¼°æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ metrics.py          # è¯„ä¼°æŒ‡æ ‡
â”‚   â””â”€â”€ evaluator.py        # è¯„ä¼°å™¨
â”œâ”€â”€ utils/                  # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ utils.py           # é€šç”¨å·¥å…·
â”‚   â””â”€â”€ logger.py          # æ—¥å¿—è®°å½•
â”œâ”€â”€ configs/               # é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ synthetic_config.json
â”œâ”€â”€ train.py              # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ inference.py          # æ¨ç†è„šæœ¬
â”œâ”€â”€ README.md            # é¡¹ç›®è¯´æ˜
â””â”€â”€ requirements.txt     # ä¾èµ–åŒ…
ğŸ› ï¸ å®‰è£…ä¾èµ–
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
conda create -n cross_modal_hash python=3.8
conda activate cross_modal_hash

# å®‰è£…PyTorchï¼ˆæ ¹æ®ä½ çš„CUDAç‰ˆæœ¬é€‰æ‹©ï¼‰
pip install torch torchvision torchaudio

# å®‰è£…å…¶ä»–ä¾èµ–
pip install transformers
pip install scikit-learn
pip install tqdm
pip install pillow
pip install pandas
pip install numpy
æˆ–è€…ä½¿ç”¨requirements.txtï¼ˆå¦‚æœæä¾›ï¼‰ï¼š

pip install -r requirements.txt
ğŸš€ å¿«é€Ÿå¼€å§‹
1. è®­ç»ƒæ¨¡å‹
ä½¿ç”¨åˆæˆæ•°æ®é›†ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰
python train.py --dataset synthetic --hash_dim 32 --batch_size 16 --num_epochs 20
ä½¿ç”¨é…ç½®æ–‡ä»¶
python train.py --config configs/synthetic_config.json
ä½¿ç”¨çœŸå®æ•°æ®é›†ï¼ˆCOCOï¼‰
python train.py \
    --dataset coco \
    --data_dir /data2/zhangchaoke/PythonProject/MyCMH/datasets/train2014 \
    --annotations_file /data2/zhangchaoke/PythonProject/MyCMH/datasets/annotations/captions_train2014.json \
    --hash_dim 64 \
    --batch_size 32 \
    --num_epochs 100
2. æ¨¡å‹æ¨ç†
æ–‡æœ¬æŸ¥è¯¢å›¾åƒ
python inference.py \
    --model_path checkpoints/best_model.pth \
    --query_text "A cat sitting on a chair" \
    --database_images image1.jpg image2.jpg image3.jpg
å›¾åƒæŸ¥è¯¢æ–‡æœ¬
python inference.py \
    --model_path checkpoints/best_model.pth \
    --query_image query_image.jpg \
    --database_texts "A cat" "A dog" "A bird"
ğŸ“Š æ¨¡å‹æ¶æ„
æ ¸å¿ƒç»„ä»¶
æ–‡æœ¬ç¼–ç å™¨ (TextEncoder)

åŸºäºé¢„è®­ç»ƒBERTæ¨¡å‹
æ”¯æŒå¤šç§BERTå˜ä½“
å¯é€‰æ‹©å†»ç»“é¢„è®­ç»ƒå‚æ•°
å›¾åƒç¼–ç å™¨ (ImageEncoder)

æ”¯æŒResNetç³»åˆ—ï¼ˆResNet50/101ï¼‰
æ”¯æŒVision Transformer
çµæ´»çš„ç‰¹å¾æå–
å“ˆå¸Œå±‚ (HashLayer)

å¤šç§æ¿€æ´»å‡½æ•°ï¼štanhã€sigmoidã€Gumbel softmax
è‡ªé€‚åº”é‡åŒ–æœºåˆ¶
ç¡®ä¿è¾“å‡ºåœ¨-1åˆ°1ä¹‹é—´
æŸå¤±å‡½æ•° (CrossModalHashLoss)

å¯¹æ¯”å­¦ä¹ æŸå¤±: InfoNCEæŸå¤±ï¼Œå­¦ä¹ è·¨æ¨¡æ€å¯¹åº”å…³ç³»
é‡åŒ–æŸå¤±: é¼“åŠ±å“ˆå¸Œç æ¥è¿‘äºŒè¿›åˆ¶å€¼
å¹³è¡¡æŸå¤±: ä¿æŒå“ˆå¸Œä½çš„å¹³è¡¡æ€§
è®­ç»ƒç­–ç•¥
å¤šä»»åŠ¡å­¦ä¹ : åŒæ—¶ä¼˜åŒ–ç‰¹å¾å­¦ä¹ å’Œå“ˆå¸Œç¼–ç 
æ¸è¿›å¼è®­ç»ƒ: é¢„çƒ­å­¦ä¹ ç‡è°ƒåº¦
æ··åˆç²¾åº¦è®­ç»ƒ: æé«˜è®­ç»ƒæ•ˆç‡
æ•°æ®å¢å¼º: ä¸°å¯Œçš„å›¾åƒå’Œæ–‡æœ¬å¢å¼ºç­–ç•¥
ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡
mAP (Mean Average Precision): å¹³å‡ç²¾åº¦å‡å€¼
Precision@K: å‰Kä¸ªç»“æœçš„ç²¾ç¡®ç‡
Recall@K: å‰Kä¸ªç»“æœçš„å¬å›ç‡
NDCG@K: å½’ä¸€åŒ–æŠ˜æŸç´¯ç§¯å¢ç›Š
æ±‰æ˜è·ç¦»: å“ˆå¸Œç ä¹‹é—´çš„è·ç¦»
âš™ï¸ é…ç½®è¯´æ˜
ä¸»è¦é…ç½®å‚æ•°
{
  "hash_dim": 64,                    // å“ˆå¸Œç ç»´åº¦
  "feature_dim": 512,                // ç‰¹å¾ç»´åº¦
  "text_model": "bert-base-uncased", // æ–‡æœ¬æ¨¡å‹
  "image_backbone": "resnet50",      // å›¾åƒéª¨å¹²ç½‘ç»œ
  "batch_size": 32,                  // æ‰¹å¤§å°
  "learning_rate": 1e-4,             // å­¦ä¹ ç‡
  "lambda_quant": 0.1,               // é‡åŒ–æŸå¤±æƒé‡
  "lambda_balance": 0.01,            // å¹³è¡¡æŸå¤±æƒé‡
  "num_epochs": 100                  // è®­ç»ƒè½®æ•°
}
æ•°æ®é›†é…ç½®
åˆæˆæ•°æ®é›†: ç”¨äºå¿«é€Ÿæµ‹è¯•å’ŒéªŒè¯
COCO: å¤§è§„æ¨¡å›¾åƒ-æ–‡æœ¬æ•°æ®é›†
Flickr30K: ç»å…¸çš„è·¨æ¨¡æ€æ£€ç´¢æ•°æ®é›†
ğŸ”§ é«˜çº§ç”¨æ³•
è‡ªå®šä¹‰æ•°æ®é›†
from data.dataset import CrossModalDataset

class MyDataset(CrossModalDataset):
    def load_annotations(self):
        # å®ç°ä½ çš„æ•°æ®åŠ è½½é€»è¾‘
        pass
è‡ªå®šä¹‰æ¨¡å‹
from models.cross_modal_hash import CrossModalHashModel

# åˆ›å»ºè‡ªå®šä¹‰é…ç½®çš„æ¨¡å‹
model = CrossModalHashModel(
    hash_dim=128,
    feature_dim=1024,
    text_model='bert-large-uncased',
    image_backbone='resnet101'
)
åˆ†å¸ƒå¼è®­ç»ƒ
python -m torch.distributed.launch \
    --nproc_per_node=4 \
    train.py \
    --distributed \
    --config configs/distributed_config.json
ğŸ“‹ å®éªŒç»“æœ
åˆæˆæ•°æ®é›†ç»“æœ
Hash Bits	mAP	P@1	P@5	P@10
32	0.85	0.92	0.88	0.84
64	0.89	0.95	0.91	0.87
128	0.91	0.96	0.93	0.89
COCOæ•°æ®é›†ç»“æœï¼ˆç¤ºä¾‹ï¼‰
Method	Hash Bits	T2I mAP	I2T mAP
Ours	64	0.72	0.68
Ours	128	0.76	0.71
ğŸ› å¸¸è§é—®é¢˜
Q: è®­ç»ƒæ—¶GPUå†…å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ
A:

å‡å°batch_size
ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆâ€“mixed_precisionï¼‰
é€‰æ‹©æ›´å°çš„æ¨¡å‹ï¼ˆå¦‚bert-baseè€Œä¸æ˜¯bert-largeï¼‰
Q: å¦‚ä½•æé«˜æ£€ç´¢ç²¾åº¦ï¼Ÿ
A:

å¢åŠ å“ˆå¸Œç ç»´åº¦
è°ƒæ•´æŸå¤±å‡½æ•°æƒé‡
ä½¿ç”¨æ›´å¼ºçš„æ•°æ®å¢å¼º
å¢åŠ è®­ç»ƒè½®æ•°
Q: æ”¯æŒå“ªäº›é¢„è®­ç»ƒæ¨¡å‹ï¼Ÿ
A:

æ–‡æœ¬ï¼šBERTç³»åˆ—ã€RoBERTaã€DistilBERTç­‰
å›¾åƒï¼šResNetç³»åˆ—ã€Vision Transformerç­‰
ğŸ¤ è´¡çŒ®æŒ‡å—
æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

Forkæœ¬é¡¹ç›®
åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (git checkout -b feature/AmazingFeature)
æäº¤æ›´æ”¹ (git commit -m 'Add some AmazingFeature')
æ¨é€åˆ°åˆ†æ”¯ (git push origin feature/AmazingFeature)
åˆ›å»ºPull Request
ğŸ“„ è®¸å¯è¯
æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ - æŸ¥çœ‹ LICENSE æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

ğŸ“š å‚è€ƒæ–‡çŒ®
Deep Cross-Modal Hashing
Learning to Hash for Indexing Big Data
Cross-Modal Retrieval with CNN Visual Features
Supervised Deep Hashing for Cross-Modal Retrieval
ğŸ“ è”ç³»æ–¹å¼
å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š

æäº¤Issue
å‘é€é‚®ä»¶åˆ° [your-email@example.com]
æ³¨æ„: è¿™æ˜¯ä¸€ä¸ªç ”ç©¶é¡¹ç›®ï¼Œä¸»è¦ç”¨äºå­¦ä¹ å’Œç ”ç©¶ç›®çš„ã€‚åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨å‰è¯·è¿›è¡Œå……åˆ†æµ‹è¯•ã€‚